# LG-VGAE-A-Local-and-Global-Collaborative-Variational-Graph-Autoencoder
LG-VGAE: A Local and Global Collaborative Variational Graph Autoencoder for Detecting Crypto Money Laundering

This work has been accepted by the journal *Knowledge and Information Systems* on May 14, 2025.

Chen, Y., Chen, Z. & Amin, H.U. LG-VGAE: a local and global collaborative variational graph autoencoder for detecting crypto money laundering. Knowl Inf Syst (2025). https://doi.org/10.1007/s10115-025-02494-3

Abstract:
Graph Neural Network (GNNs) have emerged as a promising method for anti-money laundering (AML) applications. However, existing semi-supervised GNN models often collaborate with downstream classifiers in a monotonous manner and tend to focus solely on local or global information. To address these limitations, we propose an unsupervised graph representation learning model called Local and Global Collaborative Variational Graph Autoencoder (LG-VGAE) for detecting cryptocurrency money laundering. Our model seamlessly integrates GNNs that concentrate on both local information and global structure into a unified framework. In experiments using the Elliptic dataset, the representation learned by LG-VGAE improves the Precision, Recall, and F1 Score of the Random Forest (RF) classifier by 3.7%, 7%, and 5.7%, respectively, achieving state-of-the-art results. The experimental results show that the proposed LG-VGAE can better capture financial anomalies and enhance the performance of downstream classifiers. The construction of this graph representation learning model provides a new way of introducing GNNs into AML.

Impact Statement: 
Machine learning, a crucial technique in AML, is unable to achieve acceptable results by employing only models based on statistics or graphs. This paper proposes a method that enables these two to interact naturally. The proposed graph representation learning algorithm achieves state-of-the-art results, increasing the precision of the statistics-based model by 3.7%, and raising the detection rate of money laundering crime by 7%. Furthermore, the approach's label-free premise broadens the applicability of machine learning for detecting crypto money laundering.

Data:
The Elliptic dataset is the largest real-world public dataset of cryptocurrency transfers. It is collected from the Bitcoin blockchain and presented in the graph data format, with 203,769 nodes and 234,355 edges. Nodes in the graph represent transactions, while the edge between two nodes represents the flow of bitcoins from one transaction to the next. Each node has 166 features. The first 94 features are attribute information of transactions, such as transfer time, amount, and handling fee, which we call local features in this article. The remaining 72 dimensions are graph-related features, mainly the statistics of neighbors' transactions, like maximum, minimum, standard deviation, and correlation coefficients, which are obtained from one-hop backward/forward of the center node.
The Elliptic dataset is made up of time series data, which are distributed within 49 time steps. Only 23% of these data are labeled, and only 2% of the data with labels are anomalies, accounting for 1/10 of all labeled data. The issues of label scarcity and category imbalance in this dataset are also urgent to be solved in practical AML, which makes it a worth exploring object. Furthermore, after visualizing the data using the t-SNE (t-distributed stochastic neighbor embedding) algorithm, we found that the difference between abnormal and normal samples was extremely insignificant, making the abnormal samples submerged in the enormous normal data, as shown in Figure 3. Therefore, it is hard to identify them using classic machine learning models. 
In our experiments, we choose  to work with the entire graph containing 49 time steps to learn the embeddings without using labels, allowing the LG-VGAE model to effectively capture both local and global information from the dataset. We refrained from using windowing to divide the time series data because our unsupervised learning model doesn't rely on labels, unlike supervised learning scenarios where windowing is more common due to the need to consider temporal dependencies. Furthermore, by focusing on the whole graph instead of specific time windows, our model avoids losing contextual information that could arise from dividing the data, thus preserving its performance and the ability to leverage the natural structure of the graph and inherent relationships among transactions.
In order to compare LG-VGAE with other algorithms, the experiments mentioned in this paper report their best performance index, using the first 34 time steps of data for training and the last 15 time steps of data for testing.

Elliptic Dataset link: https://www.kaggle.com/datasets/ellipticco/elliptic-data-set
